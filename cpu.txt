apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:32Z"
    generateName: mongo-mongodb-8494f5ff47-
    labels:
      app.kubernetes.io/component: mongodb
      app.kubernetes.io/instance: mongo
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: mongodb
      app.kubernetes.io/version: 7.0.12
      helm.sh/chart: mongodb-15.6.18
      pod-template-hash: 8494f5ff47
    name: mongo-mongodb-8494f5ff47-r4nw4
    namespace: database
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: mongo-mongodb-8494f5ff47
      uid: f13e498f-e350-4cba-bf2f-b05a1a6c0539
    resourceVersion: "322927716"
    uid: 8e83aef8-8230-4b9c-9f18-7b6e0d1f6f17
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: mongodb
                app.kubernetes.io/instance: mongo
                app.kubernetes.io/name: mongodb
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "false"
      - name: MONGODB_ROOT_USER
        value: jmbesada
      - name: MONGODB_ROOT_PASSWORD
        valueFrom:
          secretKeyRef:
            key: mongodb-root-password
            name: mongo-mongodb
      - name: ALLOW_EMPTY_PASSWORD
        value: "no"
      - name: MONGODB_SYSTEM_LOG_VERBOSITY
        value: "0"
      - name: MONGODB_DISABLE_SYSTEM_LOG
        value: "no"
      - name: MONGODB_DISABLE_JAVASCRIPT
        value: "no"
      - name: MONGODB_ENABLE_JOURNAL
        value: "yes"
      - name: MONGODB_PORT_NUMBER
        value: "27017"
      - name: MONGODB_ENABLE_IPV6
        value: "no"
      - name: MONGODB_ENABLE_DIRECTORY_PER_DB
        value: "no"
      image: docker.io/bitnami/mongodb:7.0.12-debian-12-r5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bitnami/scripts/ping-mongodb.sh
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 10
      name: mongodb
      ports:
      - containerPort: 27017
        name: mongodb
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bitnami/scripts/readiness-probe.sh
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 750m
          ephemeral-storage: 2Gi
          memory: 768Mi
        requests:
          cpu: 30m
          ephemeral-storage: 50Mi
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /opt/bitnami/mongodb/conf
        name: empty-dir
        subPath: app-conf-dir
      - mountPath: /opt/bitnami/mongodb/tmp
        name: empty-dir
        subPath: app-tmp-dir
      - mountPath: /opt/bitnami/mongodb/logs
        name: empty-dir
        subPath: app-logs-dir
      - mountPath: /.mongodb
        name: empty-dir
        subPath: mongosh-home
      - mountPath: /bitnami/mongodb
        name: datadir
      - mountPath: /bitnami/scripts
        name: common-scripts
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - args:
      - -ec
      - |
        ln -sf /dev/stdout "/opt/bitnami/mongodb/logs/mongodb.log"
      command:
      - /bin/bash
      image: docker.io/bitnami/mongodb:7.0.12-debian-12-r5
      imagePullPolicy: IfNotPresent
      name: log-dir
      resources:
        limits:
          cpu: 750m
          ephemeral-storage: 2Gi
          memory: 768Mi
        requests:
          cpu: 30m
          ephemeral-storage: 50Mi
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/bitnami/mongodb/logs
        name: empty-dir
        subPath: app-logs-dir
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: mongo-mongodb
    serviceAccountName: mongo-mongodb
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: empty-dir
    - configMap:
        defaultMode: 360
        name: mongo-mongodb-common-scripts
      name: common-scripts
    - name: datadir
      persistentVolumeClaim:
        claimName: mongo-mongodb
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4470e1691c2297c6fed77731339848cbf1ba71eb3c51684c2217d8f7fff71bc7
      image: docker.io/bitnami/mongodb:7.0.12-debian-12-r5
      imageID: docker.io/bitnami/mongodb@sha256:1f86c5ac9c4c12448eb482135879655eea2a8e8e2f828bd3a3d5d2014a6a003b
      lastState: {}
      name: mongodb
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:07Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://5ce6ed2a69d70c8d60c9b8eb245f96c53285a828d25a8b00d64720f2f39c8e60
      image: docker.io/bitnami/mongodb:7.0.12-debian-12-r5
      imageID: docker.io/bitnami/mongodb@sha256:1f86c5ac9c4c12448eb482135879655eea2a8e8e2f828bd3a3d5d2014a6a003b
      lastState: {}
      name: log-dir
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://5ce6ed2a69d70c8d60c9b8eb245f96c53285a828d25a8b00d64720f2f39c8e60
          exitCode: 0
          finishedAt: "2024-11-28T04:04:06Z"
          reason: Completed
          startedAt: "2024-11-28T04:04:06Z"
    phase: Running
    podIP: 10.244.0.8
    podIPs:
    - ip: 10.244.0.8
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:46Z"
    generateName: postgresql-
    labels:
      app.kubernetes.io/component: primary
      app.kubernetes.io/instance: postgresql
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/version: 16.2.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: postgresql-789d6d884c
      helm.sh/chart: postgresql-15.2.4
      statefulset.kubernetes.io/pod-name: postgresql-0
    name: postgresql-0
    namespace: database
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: postgresql
      uid: 241c0777-809d-4b44-9cba-58630a573951
    resourceVersion: "322927602"
    uid: 6d66cd55-ee92-448b-babd-636899d9afe8
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: primary
                app.kubernetes.io/instance: postgresql
                app.kubernetes.io/name: postgresql
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "false"
      - name: POSTGRESQL_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_VOLUME_DIR
        value: /bitnami/postgresql
      - name: PGDATA
        value: /bitnami/postgresql/data
      - name: POSTGRES_USER
        value: jmbesada
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: password
            name: postgresql
      - name: POSTGRES_POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: postgresql
      - name: POSTGRES_DATABASE
        value: categorizer
      - name: POSTGRESQL_ENABLE_LDAP
        value: "no"
      - name: POSTGRESQL_ENABLE_TLS
        value: "no"
      - name: POSTGRESQL_LOG_HOSTNAME
        value: "false"
      - name: POSTGRESQL_LOG_CONNECTIONS
        value: "false"
      - name: POSTGRESQL_LOG_DISCONNECTIONS
        value: "false"
      - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
        value: "off"
      - name: POSTGRESQL_CLIENT_MIN_MESSAGES
        value: error
      - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
        value: pgaudit
      image: docker.io/bitnami/postgresql:16.2.0-debian-12-r14
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - exec pg_isready -U "jmbesada" -d "dbname=categorizer" -h 127.0.0.1 -p
            5432
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: postgresql
      ports:
      - containerPort: 5432
        name: tcp-postgresql
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - -e
          - |
            exec pg_isready -U "jmbesada" -d "dbname=categorizer" -h 127.0.0.1 -p 5432
            [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 50m
          memory: 110Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /opt/bitnami/postgresql/conf
        name: empty-dir
        subPath: app-conf-dir
      - mountPath: /opt/bitnami/postgresql/tmp
        name: empty-dir
        subPath: app-tmp-dir
      - mountPath: /opt/bitnami/postgresql/logs
        name: empty-dir
        subPath: app-logs-dir
      - mountPath: /dev/shm
        name: dshm
      - mountPath: /bitnami/postgresql
        name: data
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: postgresql-0
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: postgresql
    serviceAccountName: postgresql
    subdomain: postgresql-hl
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-postgresql-0
    - emptyDir: {}
      name: empty-dir
    - emptyDir:
        medium: Memory
      name: dshm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4a1850a1af1fc2080b58b908034b20ba4b9fe5513ae9194403805592ce70b524
      image: docker.io/bitnami/postgresql:16.2.0-debian-12-r14
      imageID: docker.io/bitnami/postgresql@sha256:327c0f2a4675730e9fba642f9958f2bbea8c19fb30fccec8de8d4f4064997dd2
      lastState: {}
      name: postgresql
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:57Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.41
    podIPs:
    - ip: 10.244.0.41
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:37Z"
    generateName: categorizer-categorization-f94456ff7-
    labels:
      app.kubernetes.io/instance: categorizer
      app.kubernetes.io/name: categorization
      pod-template-hash: f94456ff7
    name: categorizer-categorization-f94456ff7-zj9xx
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: categorizer-categorization-f94456ff7
      uid: 651d984d-776a-4b1e-b142-140008966e10
    resourceVersion: "322928287"
    uid: b08aa34a-73c5-429b-b006-b1072503963e
  spec:
    containers:
    - env:
      - name: SPRING_DATASOURCE_PASSWORD
        valueFrom:
          secretKeyRef:
            key: DATASOURCE_PASSWORD
            name: categorizer
      - name: STAKATER_CATEGORIZER_CONFIGMAP
        value: a991305fdb9c6fd40855b51c99fa66da559ce951
      - name: STAKATER_CATEGORIZER_SECRET
        value: e5936dd9e60318ee5fb6a91b2c21de14789e76ba
      - name: SPRING_DATASOURCE_USERNAME
        valueFrom:
          secretKeyRef:
            key: DATASOURCE_USERNAME
            name: categorizer
      - name: MONGO_USERNAME
        valueFrom:
          secretKeyRef:
            key: MONGO_USERNAME
            name: categorizer
      - name: MONGO_PASSWORD
        valueFrom:
          secretKeyRef:
            key: MONGO_PASSWORD
            name: categorizer
      - name: AZURE_DATABASE_USERNAME
        valueFrom:
          secretKeyRef:
            key: PARAMETROS_DATABASE_USERNAME
            name: azure-vault-secret-plain
      - name: STAKATER_AZURE_VAULT_SECRET_PLAIN_SECRET
        value: c3e5e795cfda64308acd3b2ef86ac637566c3acd
      image: docker.io/actraiser/categorizer:1.0.3-SNAPSHOT
      imagePullPolicy: Always
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /management/health/liveness
          port: http
          scheme: HTTP
        initialDelaySeconds: 20
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      name: categorization
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /management/health/readiness
          port: http
          scheme: HTTP
        initialDelaySeconds: 20
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 800Mi
        requests:
          cpu: 20m
          memory: 60Mi
      securityContext: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /workspace/source/src/config
        name: application-yaml
      - mountPath: /mnt/secrets/azure-secrets
        name: azure-csi-secrets
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nr2kx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: categorizer-categorization
    serviceAccountName: categorizer-categorization
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: application.yaml
          path: application.yaml
        name: categorizer
      name: application-yaml
    - csi:
        driver: secrets-store.csi.k8s.io
        nodePublishSecretRef:
          name: azure-vault-secret
        readOnly: true
        volumeAttributes:
          secretProviderClass: azure-vault-secret-provider
      name: azure-csi-secrets
    - name: kube-api-access-nr2kx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:05:44Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:05:44Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://32cac48b764499a71f1ccbf9e63baf3fcb070dc9aa0fd2c00220e60ec62ab1d3
      image: docker.io/actraiser/categorizer:1.0.3-SNAPSHOT
      imageID: docker.io/actraiser/categorizer@sha256:4eeb2d05dedec6abf6dec74329b82c3b5e1ce8a1330a88402d9cc2efb43ad1f9
      lastState: {}
      name: categorization
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:33Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.43
    podIPs:
    - ip: 10.244.0.43
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:35Z"
    generateName: reloader-reloader-699577fcc6-
    labels:
      app: reloader-reloader
      app.kubernetes.io/managed-by: Helm
      chart: reloader-1.0.71
      group: com.stakater.platform
      heritage: Helm
      pod-template-hash: 699577fcc6
      provider: stakater
      release: reloader
      version: v1.0.71
    name: reloader-reloader-699577fcc6-62552
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: reloader-reloader-699577fcc6
      uid: f55e80eb-23e0-484b-99ce-57b0db1bb8c4
    resourceVersion: "322927524"
    uid: fe476c30-eb5e-4238-8bff-11e59cb77e84
  spec:
    containers:
    - image: ghcr.io/stakater/reloader:v1.0.71
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /live
          port: http
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: reloader-reloader
      ports:
      - containerPort: 9090
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          path: /metrics
          port: http
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6bqrh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: reloader-reloader
    serviceAccountName: reloader-reloader
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-6bqrh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b0661ae52b12d02d817573df473cfa3df959b63a35a25d2fbb60bf5942e920c2
      image: ghcr.io/stakater/reloader:v1.0.71
      imageID: ghcr.io/stakater/reloader@sha256:ffd4f293998ff491027624a9373018b0465590d0168b36f622c852ca387bf6f4
      lastState: {}
      name: reloader-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:44Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.16
    podIPs:
    - ip: 10.244.0.16
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:33Z"
    generateName: emissary-apiext-58bf4d58b-
    labels:
      app.kubernetes.io/instance: emissary-apiext
      app.kubernetes.io/managed-by: kubectl_apply_-f_aes-apiext.yaml
      app.kubernetes.io/name: emissary-apiext
      app.kubernetes.io/part-of: emissary-apiext
      pod-template-hash: 58bf4d58b
    name: emissary-apiext-58bf4d58b-q86qc
    namespace: emissary-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-apiext-58bf4d58b
      uid: fb47b727-c5e8-4ed0-97dd-808d1a26c1f7
    resourceVersion: "322927633"
    uid: ba2a36a2-7603-41f8-96fc-92d3add2590f
  spec:
    containers:
    - command:
      - apiext
      - emissary-apiext
      image: docker.io/datawire/aes:3.2.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /probes/live
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      name: emissary-apiext
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q6w2c
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: emissary-apiext
    serviceAccountName: emissary-apiext
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-q6w2c
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7ce9f22dbb88d33d9b3a468e65cab04f5cb1ce7672b1f1cb0dd8bed30e51aa64
      image: docker.io/datawire/aes:3.2.0
      imageID: docker.io/datawire/aes@sha256:d48708a2d52bb527bc49a9175c93386726ecde3b0f49ce174c4187816752bfff
      lastState: {}
      name: emissary-apiext
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:02Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.44
    podIPs:
    - ip: 10.244.0.44
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:32Z"
    generateName: emissary-apiext-58bf4d58b-
    labels:
      app.kubernetes.io/instance: emissary-apiext
      app.kubernetes.io/managed-by: kubectl_apply_-f_aes-apiext.yaml
      app.kubernetes.io/name: emissary-apiext
      app.kubernetes.io/part-of: emissary-apiext
      pod-template-hash: 58bf4d58b
    name: emissary-apiext-58bf4d58b-v8kzn
    namespace: emissary-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-apiext-58bf4d58b
      uid: fb47b727-c5e8-4ed0-97dd-808d1a26c1f7
    resourceVersion: "322927629"
    uid: fee6c57c-0933-4db9-b22a-45ef0b2017da
  spec:
    containers:
    - command:
      - apiext
      - emissary-apiext
      image: docker.io/datawire/aes:3.2.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /probes/live
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      name: emissary-apiext
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ljs86
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: emissary-apiext
    serviceAccountName: emissary-apiext
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-ljs86
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://32ebeba7830b7c942f6ac60525382fd9f3ebdc0695c4fc96e5925893faf8ea93
      image: docker.io/datawire/aes:3.2.0
      imageID: docker.io/datawire/aes@sha256:d48708a2d52bb527bc49a9175c93386726ecde3b0f49ce174c4187816752bfff
      lastState: {}
      name: emissary-apiext
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:02Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.110
    podIPs:
    - ip: 10.244.0.110
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:37Z"
    generateName: emissary-apiext-58bf4d58b-
    labels:
      app.kubernetes.io/instance: emissary-apiext
      app.kubernetes.io/managed-by: kubectl_apply_-f_aes-apiext.yaml
      app.kubernetes.io/name: emissary-apiext
      app.kubernetes.io/part-of: emissary-apiext
      pod-template-hash: 58bf4d58b
    name: emissary-apiext-58bf4d58b-zplt9
    namespace: emissary-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-apiext-58bf4d58b
      uid: fb47b727-c5e8-4ed0-97dd-808d1a26c1f7
    resourceVersion: "322927639"
    uid: ce14275a-b88d-4de6-9978-b6775df8215c
  spec:
    containers:
    - command:
      - apiext
      - emissary-apiext
      image: docker.io/datawire/aes:3.2.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /probes/live
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      name: emissary-apiext
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rtv4d
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: emissary-apiext
    serviceAccountName: emissary-apiext
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rtv4d
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://03a546c07b1474f846158698da46260ba9ef3ad29e1488113429ca168895fbf5
      image: docker.io/datawire/aes:3.2.0
      imageID: docker.io/datawire/aes@sha256:d48708a2d52bb527bc49a9175c93386726ecde3b0f49ce174c4187816752bfff
      lastState: {}
      name: emissary-apiext
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:02Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.113
    podIPs:
    - ip: 10.244.0.113
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:32Z"
    generateName: argocd-argo-cd-app-controller-9467967d7-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argo-cd
      app.kubernetes.io/version: 2.10.6
      helm.sh/chart: argo-cd-6.0.6
      pod-template-hash: 9467967d7
    name: argocd-argo-cd-app-controller-9467967d7-b8v9j
    namespace: gitops
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-argo-cd-app-controller-9467967d7
      uid: f54349ab-e19a-4e4d-87e8-ebf85d480896
    resourceVersion: "322927910"
    uid: 35f4a1d1-f3d9-4988-9297-025ed8637411
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: controller
                app.kubernetes.io/instance: argocd
                app.kubernetes.io/name: argo-cd
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: true
    containers:
    - args:
      - argocd-application-controller
      - --status-processors
      - "20"
      - --operation-processors
      - "10"
      - --app-resync
      - "180"
      - --self-heal-timeout-seconds
      - "5"
      - --repo-server
      - argocd-argo-cd-repo-server:8081
      - --logformat
      - text
      - --loglevel
      - info
      - --redis
      - argocd-redis-master:6379
      env:
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8082
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 8082
        name: controller
        protocol: TCP
      - containerPort: 8082
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: 8082
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 10m
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/server/tls
        name: argocd-repo-server-tls
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5lsx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - args:
      - -ec
      - |
        #!/bin/bash

        set -o errexit
        set -o nounset
        set -o pipefail

        . /opt/bitnami/scripts/libos.sh
        . /opt/bitnami/scripts/liblog.sh

        check_redis_connection() {
          local result="$(redis-cli -h argocd-redis-master -p 6379  PING)"
          if [[ "$result" != "PONG" ]]; then
            false
          fi
        }

        info "Checking redis connection..."
        if ! retry_while "check_redis_connection"; then
            error "Could not connect to the Redis server"
            return 1
        else
            info "Connected to the Redis instance"
        fi
      command:
      - /bin/bash
      env:
      - name: REDISCLI_AUTH
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imagePullPolicy: IfNotPresent
      name: wait-for-redis
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5lsx
        readOnly: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: argocd-argo-cd-argocd-app-controller
    serviceAccountName: argocd-argo-cd-argocd-app-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: empty-dir
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-c5lsx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:19Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://44e7fec7422c3f56a79ddb5c8fac8efc2f4b09bbeb8109c10d21f414e55760b9
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imageID: docker.io/bitnami/argo-cd@sha256:41cf9e5cbf9c016ca5172fdfacf6cc185a544eb2b0a0d5d2d75c54fde012e71a
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:34Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://19df2968b5aa4de1ea9bcf7d7b1a9814febfef69af57006415ecb796368f274a
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imageID: docker.io/bitnami/redis@sha256:636c88d6460b42d7029ece70ae41b5e51b40acbf125d24cc1a69df20bac2bf63
      lastState: {}
      name: wait-for-redis
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://19df2968b5aa4de1ea9bcf7d7b1a9814febfef69af57006415ecb796368f274a
          exitCode: 0
          finishedAt: "2024-11-28T04:04:18Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:47Z"
    phase: Running
    podIP: 10.244.0.111
    podIPs:
    - ip: 10.244.0.111
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:36Z"
    generateName: argocd-argo-cd-repo-server-79b5b4846b-
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argo-cd
      app.kubernetes.io/version: 2.10.6
      helm.sh/chart: argo-cd-6.0.6
      pod-template-hash: 79b5b4846b
    name: argocd-argo-cd-repo-server-79b5b4846b-flwzn
    namespace: gitops
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-argo-cd-repo-server-79b5b4846b
      uid: 126e8236-ba60-4712-aef3-30d2f362f918
    resourceVersion: "322927966"
    uid: f9896ac5-5b8b-4cde-bf4a-a490e84fe9aa
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: repo-server
                app.kubernetes.io/instance: argocd
                app.kubernetes.io/name: argo-cd
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: true
    containers:
    - args:
      - argocd-repo-server
      - --logformat
      - text
      - --loglevel
      - info
      - --redis
      - argocd-redis-master:6379
      env:
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: 8081
        timeoutSeconds: 1
      name: argocd-repo-server
      ports:
      - containerPort: 8081
        name: repo-server
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: 8081
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 150m
          ephemeral-storage: 1Gi
          memory: 192Mi
        requests:
          cpu: 100m
          ephemeral-storage: 50Mi
          memory: 128Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/ssh
        name: ssh-known-hosts
      - mountPath: /app/config/server/tls
        name: argocd-repo-server-tls
      - mountPath: /app/config/gpg/keys
        name: empty-dir
        subPath: app-keys-dir
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dh2vx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - args:
      - -ec
      - |
        #!/bin/bash

        set -o errexit
        set -o nounset
        set -o pipefail

        . /opt/bitnami/scripts/libos.sh
        . /opt/bitnami/scripts/liblog.sh

        check_redis_connection() {
          local result="$(redis-cli -h argocd-redis-master -p 6379  PING)"
          if [[ "$result" != "PONG" ]]; then
            false
          fi
        }

        info "Checking redis connection..."
        if ! retry_while "check_redis_connection"; then
            error "Could not connect to the Redis server"
            return 1
        else
            info "Connected to the Redis instance"
        fi
      command:
      - /bin/bash
      env:
      - name: REDISCLI_AUTH
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imagePullPolicy: IfNotPresent
      name: wait-for-redis
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dh2vx
        readOnly: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: argocd-argo-cd-argocd-repo-server
    serviceAccountName: argocd-argo-cd-argocd-repo-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: argocd-ssh-known-hosts-cm
      name: ssh-known-hosts
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - emptyDir: {}
      name: empty-dir
    - name: kube-api-access-dh2vx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://40670d0afbf0260d45a645e8d1a5d7d26a89d928419d481ae78b2e627de9622e
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imageID: docker.io/bitnami/argo-cd@sha256:41cf9e5cbf9c016ca5172fdfacf6cc185a544eb2b0a0d5d2d75c54fde012e71a
      lastState: {}
      name: argocd-repo-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:34Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://dcbd7376e8c7c206811da8be8f9d38a934ef30b8acc76c822b268bed4986ee34
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imageID: docker.io/bitnami/redis@sha256:636c88d6460b42d7029ece70ae41b5e51b40acbf125d24cc1a69df20bac2bf63
      lastState: {}
      name: wait-for-redis
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://dcbd7376e8c7c206811da8be8f9d38a934ef30b8acc76c822b268bed4986ee34
          exitCode: 0
          finishedAt: "2024-11-28T04:04:18Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:47Z"
    phase: Running
    podIP: 10.244.0.77
    podIPs:
    - ip: 10.244.0.77
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:34Z"
    generateName: argocd-argo-cd-server-c4d555d64-
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argo-cd
      app.kubernetes.io/version: 2.10.6
      helm.sh/chart: argo-cd-6.0.6
      pod-template-hash: c4d555d64
    name: argocd-argo-cd-server-c4d555d64-65mvq
    namespace: gitops
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-argo-cd-server-c4d555d64
      uid: 3a847aa9-1ea8-427d-a1e2-6ee1b3069934
    resourceVersion: "322927905"
    uid: b784dd45-d0a4-4818-93f6-c12e992f996a
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: customLabels
                app.kubernetes.io/instance: argocd
                app.kubernetes.io/name: argo-cd
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: true
    containers:
    - args:
      - argocd-server
      - --staticassets
      - /opt/bitnami/argo-cd/app
      - --repo-server
      - argocd-argo-cd-repo-server:8081
      - --logformat
      - text
      - --loglevel
      - info
      - --redis
      - argocd-redis-master:6379
      - --insecure
      env:
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: argocd-server
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 10m
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /app/config/ssh
        name: ssh-known-hosts
      - mountPath: /app/config/server/tls
        name: argocd-repo-server-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p755w
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - args:
      - -ec
      - |
        #!/bin/bash

        set -o errexit
        set -o nounset
        set -o pipefail

        . /opt/bitnami/scripts/libos.sh
        . /opt/bitnami/scripts/liblog.sh

        check_redis_connection() {
          local result="$(redis-cli -h argocd-redis-master -p 6379  PING)"
          if [[ "$result" != "PONG" ]]; then
            false
          fi
        }

        info "Checking redis connection..."
        if ! retry_while "check_redis_connection"; then
            error "Could not connect to the Redis server"
            return 1
        else
            info "Connected to the Redis instance"
        fi
      command:
      - /bin/bash
      env:
      - name: REDISCLI_AUTH
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imagePullPolicy: IfNotPresent
      name: wait-for-redis
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p755w
        readOnly: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: argocd-argo-cd-argocd-server
    serviceAccountName: argocd-argo-cd-argocd-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: empty-dir
    - configMap:
        defaultMode: 420
        name: argocd-ssh-known-hosts-cm
      name: ssh-known-hosts
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-p755w
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e268fbd24c813eedaee0dc21cc7fc58166b332ff20642664cb7c5eba8bd3a562
      image: docker.io/bitnami/argo-cd:2.10.6-debian-12-r1
      imageID: docker.io/bitnami/argo-cd@sha256:41cf9e5cbf9c016ca5172fdfacf6cc185a544eb2b0a0d5d2d75c54fde012e71a
      lastState: {}
      name: argocd-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:34Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://528e34b46a6c2cc019a93c632f53afd3d26b534e47ab241fda86340819fb2bdb
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imageID: docker.io/bitnami/redis@sha256:636c88d6460b42d7029ece70ae41b5e51b40acbf125d24cc1a69df20bac2bf63
      lastState: {}
      name: wait-for-redis
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://528e34b46a6c2cc019a93c632f53afd3d26b534e47ab241fda86340819fb2bdb
          exitCode: 0
          finishedAt: "2024-11-28T04:04:18Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:46Z"
    phase: Running
    podIP: 10.244.0.7
    podIPs:
    - ip: 10.244.0.7
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
      checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
      checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
      checksum/secret: fc47c87a11fc537130dcb046d1f5ca1c56af91a97fbb65ad71737919f7341881
    creationTimestamp: "2024-11-28T04:01:39Z"
    generateName: argocd-redis-master-
    labels:
      app.kubernetes.io/component: master
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: redis
      app.kubernetes.io/version: 7.2.4
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: argocd-redis-master-6ccc5d4f9f
      helm.sh/chart: redis-19.0.2
      statefulset.kubernetes.io/pod-name: argocd-redis-master-0
    name: argocd-redis-master-0
    namespace: gitops
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: argocd-redis-master
      uid: 3fd94f36-5f93-4a6c-98ff-c5d5222db8f8
    resourceVersion: "322927671"
    uid: fbc0899e-c9df-4fe1-a6e4-28328c73f56c
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: master
                app.kubernetes.io/instance: argocd
                app.kubernetes.io/name: redis
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - args:
      - -c
      - /opt/bitnami/scripts/start-scripts/start-master.sh
      command:
      - /bin/bash
      env:
      - name: BITNAMI_DEBUG
        value: "false"
      - name: REDIS_REPLICATION_MODE
        value: master
      - name: ALLOW_EMPTY_PASSWORD
        value: "no"
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-password
            name: argocd-redis
      - name: REDIS_TLS_ENABLED
        value: "no"
      - name: REDIS_PORT
        value: "6379"
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - sh
          - -c
          - /health/ping_liveness_local.sh 5
        failureThreshold: 5
        initialDelaySeconds: 20
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 6
      name: redis
      ports:
      - containerPort: 6379
        name: redis
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - /health/ping_readiness_local.sh 1
        failureThreshold: 5
        initialDelaySeconds: 20
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 2
      resources:
        limits:
          cpu: 150m
          ephemeral-storage: 1Gi
          memory: 192Mi
        requests:
          cpu: 100m
          ephemeral-storage: 50Mi
          memory: 128Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/bitnami/scripts/start-scripts
        name: start-scripts
      - mountPath: /health
        name: health
      - mountPath: /data
        name: redis-data
      - mountPath: /opt/bitnami/redis/mounted-etc
        name: config
      - mountPath: /opt/bitnami/redis/etc/
        name: empty-dir
        subPath: app-conf-dir
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: argocd-redis-master-0
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: argocd-redis-master
    serviceAccountName: argocd-redis-master
    subdomain: argocd-redis-headless
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: redis-data
      persistentVolumeClaim:
        claimName: redis-data-argocd-redis-master-0
    - configMap:
        defaultMode: 493
        name: argocd-redis-scripts
      name: start-scripts
    - configMap:
        defaultMode: 493
        name: argocd-redis-health
      name: health
    - configMap:
        defaultMode: 420
        name: argocd-redis-configuration
      name: config
    - emptyDir: {}
      name: empty-dir
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f3ff4145b10fd7a71034ea857f7485b3bb038e05ac5a12d917c40fa40f12a330
      image: docker.io/bitnami/redis:7.2.4-debian-12-r11
      imageID: docker.io/bitnami/redis@sha256:636c88d6460b42d7029ece70ae41b5e51b40acbf125d24cc1a69df20bac2bf63
      lastState: {}
      name: redis
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:47Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.22
    podIPs:
    - ip: 10.244.0.22
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-30T15:25:51Z"
    generateName: activator-7c7c8bcf94-
    labels:
      app: activator
      app.kubernetes.io/component: activator
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: 1.16.0
      pod-template-hash: 7c7c8bcf94
      role: activator
    name: activator-7c7c8bcf94-9wl8d
    namespace: knative-serving
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: activator-7c7c8bcf94
      uid: 4a668ea4-94bf-4253-ab93-dd8b55ae9b20
    resourceVersion: "324199696"
    uid: a95664a1-0977-42d3-8c44-16c7a6925bd3
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: activator
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: GOGC
        value: "500"
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: METRICS_DOMAIN
        value: knative.dev/internal/serving
      image: gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:24c19cbee078925b91cd2e85082b581d53b218b410c083b1005dc06dc549b1d3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 12
        httpGet:
          path: /
          port: 8012
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: activator
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8012
        name: http1
        protocol: TCP
      - containerPort: 8013
        name: h2c
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          path: /
          port: 8012
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 600Mi
        requests:
          cpu: 50m
          memory: 60Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9k8vd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: activator
    serviceAccountName: activator
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-9k8vd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:25:58Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:25:58Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://34354b9fc549770482512fe27fe8bef21d1a804beb3187046132feb88e210f48
      image: sha256:75d76ff65412a5360420b926673aa1b588b4fd1bfc26ed6c3b2e21924f2a7412
      imageID: gcr.io/knative-releases/knative.dev/serving/cmd/activator@sha256:24c19cbee078925b91cd2e85082b581d53b218b410c083b1005dc06dc549b1d3
      lastState: {}
      name: activator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-30T15:25:57Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.118
    podIPs:
    - ip: 10.244.0.118
    qosClass: Burstable
    startTime: "2024-11-30T15:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-30T15:14:41Z"
    generateName: autoscaler-6c7bf97997-
    labels:
      app: autoscaler
      app.kubernetes.io/component: autoscaler
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: 1.16.0
      pod-template-hash: 6c7bf97997
    name: autoscaler-6c7bf97997-rsc89
    namespace: knative-serving
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: autoscaler-6c7bf97997
      uid: 1d4c68e2-3dc9-4bae-8799-89e2cd7086c4
    resourceVersion: "324194556"
    uid: 4f56f689-662d-4ee1-af90-feb0dfb1fd4a
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: autoscaler
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: METRICS_DOMAIN
        value: knative.dev/serving
      image: gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:5e9236452d89363957d4e7e249d57740a8fcd946aed23f8518d94962bf440250
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: autoscaler
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8080
        name: websocket
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1000Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9l5sm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: controller
    serviceAccountName: controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-9l5sm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e01917462fbf52a008555db70d378955977dbd3f980b43b4510023a8e9547324
      image: sha256:07d2818f44eb4d059636d479f4d563a37335fe2dd20e414363b3df2c494359d1
      imageID: gcr.io/knative-releases/knative.dev/serving/cmd/autoscaler@sha256:5e9236452d89363957d4e7e249d57740a8fcd946aed23f8518d94962bf440250
      lastState: {}
      name: autoscaler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-30T15:14:48Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.105
    podIPs:
    - ip: 10.244.0.105
    qosClass: Burstable
    startTime: "2024-11-30T15:14:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-30T15:14:41Z"
    generateName: controller-5b54cd98c-
    labels:
      app: controller
      app.kubernetes.io/component: controller
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: 1.16.0
      pod-template-hash: 5b54cd98c
    name: controller-5b54cd98c-q7rjw
    namespace: knative-serving
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: controller-5b54cd98c
      uid: 82839bbd-33a6-4c10-ace3-93b67e0c3520
    resourceVersion: "324194541"
    uid: 267c896b-bfcf-460f-b5b3-26cc903164db
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: controller
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: METRICS_DOMAIN
        value: knative.dev/internal/serving
      image: gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:5fb22b052e6bc98a1a6bbb68c0282ddb50744702acee6d83110302bc990666e9
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /health
          port: probes
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8080
        name: probes
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: probes
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 1000Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rnrwb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: controller
    serviceAccountName: controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rnrwb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:14:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d81b6e200f6dcc2835726a7201e2db029e09774b46281508761b840980e60235
      image: sha256:ea7dc6abf93e78dd678baacabf933d07bf7f5e9cd7f4df649d7454ccff704cdc
      imageID: gcr.io/knative-releases/knative.dev/serving/cmd/controller@sha256:5fb22b052e6bc98a1a6bbb68c0282ddb50744702acee6d83110302bc990666e9
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-30T15:14:47Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.67
    podIPs:
    - ip: 10.244.0.67
    qosClass: Burstable
    startTime: "2024-11-30T15:14:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9090"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-30T15:17:28Z"
    generateName: net-kourier-controller-5db85876d8-
    labels:
      app: net-kourier-controller
      pod-template-hash: 5db85876d8
    name: net-kourier-controller-5db85876d8-xhvx9
    namespace: knative-serving
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: net-kourier-controller-5db85876d8
      uid: a18b03d1-91eb-4b69-9c51-3a97fa0199b9
    resourceVersion: "324197765"
    uid: b2751fe6-ceb5-4c16-a52f-f8f9cf9a8a48
  spec:
    containers:
    - env:
      - name: CERTS_SECRET_NAMESPACE
      - name: CERTS_SECRET_NAME
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: METRICS_DOMAIN
        value: knative.dev/samples
      - name: KOURIER_GATEWAY_NAMESPACE
        value: kourier-system
      - name: ENABLE_SECRET_INFORMER_FILTERING_BY_CERT_UID
        value: "false"
      - name: KUBE_API_BURST
        value: "200"
      - name: KUBE_API_QPS
        value: "200"
      image: gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier@sha256:b53b3b680ef1f3cca83740d9e667f60b3581574b95a365dc7a1b9ce3fdd96aa6
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        grpc:
          port: 18000
          service: ""
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 18000
        name: http2-xds
        protocol: TCP
      - containerPort: 9090
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        grpc:
          port: 18000
          service: ""
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 500Mi
        requests:
          cpu: 200m
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m8hln
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: net-kourier
    serviceAccountName: net-kourier
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-m8hln
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:21:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:21:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:21:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:21:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://434d6586d10b5664d7f93e39bc87aadd8e439298660262e09c0abd91c715eba1
      image: sha256:26e26abb1c108f131369e320ba0f787b88862da30f03875aadba00f2e6ec1165
      imageID: gcr.io/knative-releases/knative.dev/net-kourier/cmd/kourier@sha256:b53b3b680ef1f3cca83740d9e667f60b3581574b95a365dc7a1b9ce3fdd96aa6
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-30T15:21:41Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.25
    podIPs:
    - ip: 10.244.0.25
    qosClass: Burstable
    startTime: "2024-11-30T15:21:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-30T15:14:41Z"
    generateName: webhook-56ffd84996-
    labels:
      app: webhook
      app.kubernetes.io/component: webhook
      app.kubernetes.io/name: knative-serving
      app.kubernetes.io/version: 1.16.0
      pod-template-hash: 56ffd84996
      role: webhook
    name: webhook-56ffd84996-5fq8r
    namespace: knative-serving
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: webhook-56ffd84996
      uid: 70877563-0cb1-40ef-857f-3dc617c6d519
    resourceVersion: "324197051"
    uid: 2d76ae0b-4084-4512-a1bf-6f6cdca993c5
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app: webhook
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: WEBHOOK_NAME
        value: webhook
      - name: WEBHOOK_PORT
        value: "8443"
      - name: METRICS_DOMAIN
        value: knative.dev/internal/serving
      image: gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:0fb5a4245aa4737d443658754464cd0a076de959fe14623fb9e9d31318ccce24
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: webhook
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8443
        name: https-webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-v4gqm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: controller
    serviceAccountName: controller
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-v4gqm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:20:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:20:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:20:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:20:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d24792624d257e602634cee281047190bf4fe5f9aaf02f344f20779e26052b3c
      image: sha256:f2a42b55949f2f29c0a43b67bf46843ade28f7f3dd22d10c6d1b5fb8bd17b704
      imageID: gcr.io/knative-releases/knative.dev/serving/cmd/webhook@sha256:0fb5a4245aa4737d443658754464cd0a076de959fe14623fb9e9d31318ccce24
      lastState: {}
      name: webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-30T15:20:14Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.107
    podIPs:
    - ip: 10.244.0.107
    qosClass: Burstable
    startTime: "2024-11-30T15:20:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      networking.knative.dev/poke: v0.26
      prometheus.io/path: /stats/prometheus
      prometheus.io/port: "9000"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-30T15:17:29Z"
    generateName: 3scale-kourier-gateway-7f9db75546-
    labels:
      app: 3scale-kourier-gateway
      pod-template-hash: 7f9db75546
    name: 3scale-kourier-gateway-7f9db75546-ssz6v
    namespace: kourier-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: 3scale-kourier-gateway-7f9db75546
      uid: bf04c157-d585-4e84-bf21-70a5399afef3
    resourceVersion: "324195759"
    uid: 2e0eb885-d4f6-4232-8d43-a7525be3dafc
  spec:
    containers:
    - args:
      - --base-id 1
      - -c /tmp/config/envoy-bootstrap.yaml
      - --log-level info
      - --drain-time-s $(DRAIN_TIME_SECONDS)
      - --drain-strategy immediate
      command:
      - /usr/local/bin/envoy
      env:
      - name: DRAIN_TIME_SECONDS
        value: "15"
      image: docker.io/envoyproxy/envoy:v1.31-latest
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/sh
            - -c
            - curl -X POST http://localhost:9901/drain_listeners?graceful; sleep $DRAIN_TIME_SECONDS
      livenessProbe:
        failureThreshold: 6
        httpGet:
          httpHeaders:
          - name: Host
            value: internalkourier
          path: /ready
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      name: kourier-gateway
      ports:
      - containerPort: 8080
        name: http2-external
        protocol: TCP
      - containerPort: 8081
        name: http2-internal
        protocol: TCP
      - containerPort: 8443
        name: https-external
        protocol: TCP
      - containerPort: 8090
        name: http-probe
        protocol: TCP
      - containerPort: 9443
        name: https-probe
        protocol: TCP
      - containerPort: 9000
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          httpHeaders:
          - name: Host
            value: internalkourier
          path: /ready
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 800Mi
        requests:
          cpu: 200m
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/config
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-685fw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: josemy-registry
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: kourier-bootstrap
      name: config-volume
    - name: kube-api-access-685fw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-30T15:17:29Z"
      message: '0/1 nodes are available: 1 Insufficient cpu. preemption: 0/1 nodes
        are available: 1 No preemption victims found for incoming pod..'
      reason: Unschedulable
      status: "False"
      type: PodScheduled
    phase: Pending
    qosClass: Burstable
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: privileged-containers,non-root-user,resource-requirements,hostpath-volume
      container.apparmor.security.beta.kubernetes.io/apply-sysctl-overwrites: unconfined
      container.apparmor.security.beta.kubernetes.io/cilium-agent: unconfined
      container.apparmor.security.beta.kubernetes.io/clean-cilium-state: unconfined
      container.apparmor.security.beta.kubernetes.io/mount-cgroup: unconfined
      kubectl.kubernetes.io/default-container: cilium-agent
      prometheus.io/port: "9090"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: cilium-
    labels:
      app.kubernetes.io/name: cilium-agent
      app.kubernetes.io/part-of: cilium
      controller-revision-hash: 568f68778b
      doks.digitalocean.com/managed: "true"
      k8s-app: cilium
      kubernetes.io/cluster-service: "true"
      pod-template-generation: "22"
    name: cilium-kdbnl
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: cilium
      uid: ab4c5bf1-b680-4b21-8719-f6dc8d4f6c88
    resourceVersion: "322927039"
    uid: 41e3c8c0-cbb9-49aa-9b34-181f7e1d8798
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              k8s-app: cilium
          topologyKey: kubernetes.io/hostname
    automountServiceAccountToken: true
    containers:
    - args:
      - --config-dir=/tmp/cilium/config-map
      - --k8s-api-server=https://115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      - --ipv4-native-routing-cidr=10.244.0.0/16
      command:
      - cilium-agent
      env:
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CILIUM_K8S_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CILIUM_CLUSTERMESH_CONFIG
        value: /var/lib/cilium/clustermesh/
      - name: KUBERNETES_SERVICE_HOST
        value: 115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      lifecycle:
        postStart:
          exec:
            command:
            - bash
            - -c
            - |
              set -o errexit
              set -o pipefail
              set -o nounset

              # When running in AWS ENI mode, it's likely that 'aws-node' has
              # had a chance to install SNAT iptables rules. These can result
              # in dropped traffic, so we should attempt to remove them.
              # We do it using a 'postStart' hook since this may need to run
              # for nodes which might have already been init'ed but may still
              # have dangling rules. This is safe because there are no
              # dependencies on anything that is part of the startup script
              # itself, and can be safely run multiple times per node (e.g. in
              # case of a restart).
              if [[ "$(iptables-save | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')" != "0" ]];
              then
                  echo 'Deleting iptables rules created by the AWS CNI VPC plugin'
                  iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN' | iptables-restore
              fi
              echo 'Done!'
        preStop:
          exec:
            command:
            - /cni-uninstall.sh
      livenessProbe:
        failureThreshold: 10
        httpGet:
          host: 127.0.0.1
          httpHeaders:
          - name: brief
            value: "true"
          path: /healthz
          port: 9879
          scheme: HTTP
        initialDelaySeconds: 120
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      name: cilium-agent
      ports:
      - containerPort: 4244
        hostPort: 4244
        name: peer-service
        protocol: TCP
      - containerPort: 9090
        hostPort: 9090
        name: prometheus
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 127.0.0.1
          httpHeaders:
          - name: brief
            value: "true"
          path: /healthz
          port: 9879
          scheme: HTTP
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 300m
          memory: 300Mi
      securityContext:
        capabilities:
          add:
          - CHOWN
          - KILL
          - NET_ADMIN
          - NET_RAW
          - IPC_LOCK
          - SYS_MODULE
          - SYS_ADMIN
          - SYS_RESOURCE
          - DAC_OVERRIDE
          - FOWNER
          - SETGID
          - SETUID
          drop:
          - ALL
        seLinuxOptions:
          level: s0
          type: spc_t
      startupProbe:
        failureThreshold: 105
        httpGet:
          host: 127.0.0.1
          httpHeaders:
          - name: brief
            value: "true"
          path: /healthz
          port: 9879
          scheme: HTTP
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 1
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/proc/sys/net
        name: host-proc-sys-net
      - mountPath: /host/proc/sys/kernel
        name: host-proc-sys-kernel
      - mountPath: /sys/fs/bpf
        mountPropagation: HostToContainer
        name: bpf-maps
      - mountPath: /var/run/cilium
        name: cilium-run
      - mountPath: /host/etc/cni/net.d
        name: etc-cni-netd
      - mountPath: /var/lib/cilium/clustermesh
        name: clustermesh-secrets
        readOnly: true
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/lib/cilium/tls/hubble
        name: hubble-tls
        readOnly: true
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - bash
      - -e
      - -c
      - |
        # This will get the node object for the local node and search through
        # the assigned addresses in the object in order to check whether CCM
        # already set the internal AND external IP since cilium needs both
        # for a clean startup.
        # The grep matches regardless of the order of IPs.
        until /host/usr/bin/kubectl get node ${HOSTNAME} -o jsonpath="{.status.addresses[*].type}" | grep -E "InternalIP.*ExternalIP|ExternalIP.*InternalIP"; do echo "waiting for CCM to store internal and external IP addresses in node object: ${HOSTNAME}" && sleep 3; done;
      env:
      - name: KUBERNETES_SERVICE_HOST
        value: 115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: delay-cilium-for-ccm
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/usr/bin/kubectl
        name: host-kubectl
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - command:
      - cilium
      - build-config
      - --source=config-map:cilium-config
      env:
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: CILIUM_K8S_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: KUBERNETES_SERVICE_HOST
        value: 115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: config
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - command:
      - sh
      - -ec
      - |
        cp /usr/bin/cilium-mount /hostbin/cilium-mount;
        nsenter --cgroup=/hostproc/1/ns/cgroup --mount=/hostproc/1/ns/mnt "${BIN_PATH}/cilium-mount" $CGROUP_ROOT;
        rm /hostbin/cilium-mount
      env:
      - name: CGROUP_ROOT
        value: /run/cilium/cgroupv2
      - name: BIN_PATH
        value: /opt/cni/bin
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: mount-cgroup
      resources: {}
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
          - SYS_CHROOT
          - SYS_PTRACE
          drop:
          - ALL
        seLinuxOptions:
          level: s0
          type: spc_t
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /hostproc
        name: hostproc
      - mountPath: /hostbin
        name: cni-path
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - command:
      - sh
      - -ec
      - |
        cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;
        nsenter --mount=/hostproc/1/ns/mnt "${BIN_PATH}/cilium-sysctlfix";
        rm /hostbin/cilium-sysctlfix
      env:
      - name: BIN_PATH
        value: /opt/cni/bin
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: apply-sysctl-overwrites
      resources: {}
      securityContext:
        capabilities:
          add:
          - SYS_ADMIN
          - SYS_CHROOT
          - SYS_PTRACE
          drop:
          - ALL
        seLinuxOptions:
          level: s0
          type: spc_t
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /hostproc
        name: hostproc
      - mountPath: /hostbin
        name: cni-path
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - args:
      - mount | grep "/sys/fs/bpf type bpf" || mount -t bpf bpf /sys/fs/bpf
      command:
      - /bin/bash
      - -c
      - --
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: mount-bpf-fs
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /sys/fs/bpf
        mountPropagation: Bidirectional
        name: bpf-maps
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - command:
      - /init-container.sh
      env:
      - name: CILIUM_ALL_STATE
        valueFrom:
          configMapKeyRef:
            key: clean-cilium-state
            name: cilium-config
            optional: true
      - name: CILIUM_BPF_STATE
        valueFrom:
          configMapKeyRef:
            key: clean-cilium-bpf-state
            name: cilium-config
            optional: true
      - name: KUBERNETES_SERVICE_HOST
        value: 115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: clean-cilium-state
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - SYS_MODULE
          - SYS_ADMIN
          - SYS_RESOURCE
          drop:
          - ALL
        seLinuxOptions:
          level: s0
          type: spc_t
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /sys/fs/bpf
        name: bpf-maps
      - mountPath: /run/cilium/cgroupv2
        mountPropagation: HostToContainer
        name: cilium-cgroup
      - mountPath: /var/run/cilium
        name: cilium-run
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    - command:
      - /install-plugin.sh
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imagePullPolicy: IfNotPresent
      name: install-cni-binaries
      resources:
        requests:
          cpu: 100m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - ALL
        seLinuxOptions:
          level: s0
          type: spc_t
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-path
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6zg6c
        readOnly: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: cilium
    serviceAccountName: cilium
    terminationGracePeriodSeconds: 1
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /usr/bin/kubectl
        type: File
      name: host-kubectl
    - emptyDir: {}
      name: tmp
    - hostPath:
        path: /var/run/cilium
        type: DirectoryOrCreate
      name: cilium-run
    - hostPath:
        path: /sys/fs/bpf
        type: DirectoryOrCreate
      name: bpf-maps
    - hostPath:
        path: /proc
        type: Directory
      name: hostproc
    - hostPath:
        path: /run/cilium/cgroupv2
        type: DirectoryOrCreate
      name: cilium-cgroup
    - hostPath:
        path: /opt/cni/bin
        type: DirectoryOrCreate
      name: cni-path
    - hostPath:
        path: /etc/cni/net.d
        type: DirectoryOrCreate
      name: etc-cni-netd
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: clustermesh-secrets
      projected:
        defaultMode: 256
        sources:
        - secret:
            name: cilium-clustermesh
            optional: true
        - secret:
            items:
            - key: tls.key
              path: common-etcd-client.key
            - key: tls.crt
              path: common-etcd-client.crt
            - key: ca.crt
              path: common-etcd-client-ca.crt
            name: clustermesh-apiserver-remote-cert
            optional: true
    - hostPath:
        path: /proc/sys/net
        type: Directory
      name: host-proc-sys-net
    - hostPath:
        path: /proc/sys/kernel
        type: Directory
      name: host-proc-sys-kernel
    - name: hubble-tls
      projected:
        defaultMode: 256
        sources:
        - secret:
            items:
            - key: tls.crt
              path: server.crt
            - key: tls.key
              path: server.key
            - key: ca.crt
              path: client-ca.crt
            name: hubble-server-certs
            optional: true
    - name: kube-api-access-6zg6c
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://78741ed31ee9715ecaebbe42cd85d37faf5dd7a8299abb2631d82b3124eb5b0e
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: cilium-agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:08Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://d1f171504e06de637d36c397e4536c593f0bcace8057b1b8ab40c110e83ff39f
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: delay-cilium-for-ccm
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://d1f171504e06de637d36c397e4536c593f0bcace8057b1b8ab40c110e83ff39f
          exitCode: 0
          finishedAt: "2024-11-28T04:03:02Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:02Z"
    - containerID: containerd://aa79407431d9ba629f2624151ec1d4a06635e857d34043b73d74b1389b75d18f
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: config
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://aa79407431d9ba629f2624151ec1d4a06635e857d34043b73d74b1389b75d18f
          exitCode: 0
          finishedAt: "2024-11-28T04:03:03Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:02Z"
    - containerID: containerd://c4bc72739e6a0a67814cbffc736f583a52035372d0d72899c962ae1b02d6a074
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: mount-cgroup
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c4bc72739e6a0a67814cbffc736f583a52035372d0d72899c962ae1b02d6a074
          exitCode: 0
          finishedAt: "2024-11-28T04:03:03Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:03Z"
    - containerID: containerd://3bd9094c591a5d66307d1c36cc1c276ff7e7c3f8fd5428babcdfe262e03e6b91
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: apply-sysctl-overwrites
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://3bd9094c591a5d66307d1c36cc1c276ff7e7c3f8fd5428babcdfe262e03e6b91
          exitCode: 0
          finishedAt: "2024-11-28T04:03:04Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:04Z"
    - containerID: containerd://845d2428821a54aee92422b3b14ff506a5a1786596c14a0c32c3b835e0fb4249
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: mount-bpf-fs
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://845d2428821a54aee92422b3b14ff506a5a1786596c14a0c32c3b835e0fb4249
          exitCode: 0
          finishedAt: "2024-11-28T04:03:05Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:05Z"
    - containerID: containerd://956a350c69e84574b95884b9617e37c88a11166362776294b585d7d819b37e28
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: clean-cilium-state
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://956a350c69e84574b95884b9617e37c88a11166362776294b585d7d819b37e28
          exitCode: 0
          finishedAt: "2024-11-28T04:03:06Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:06Z"
    - containerID: containerd://c51593cb8af29e0b80ab7ac128dd346d08c3f33666a25837a90a71382348d267
      image: docker.io/digitalocean/cilium:v1.14.14-conformance-fix
      imageID: docker.io/digitalocean/cilium@sha256:241e51bbd436c0d3b6c9b438e26bbf6808e91e25559f04ceb3638f83c3d73549
      lastState: {}
      name: install-cni-binaries
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c51593cb8af29e0b80ab7ac128dd346d08c3f33666a25837a90a71382348d267
          exitCode: 0
          finishedAt: "2024-11-28T04:03:08Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:07Z"
    phase: Running
    podIP: 10.114.0.3
    podIPs:
    - ip: 10.114.0.3
    qosClass: Burstable
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:31Z"
    generateName: coredns-5dd67759cd-
    labels:
      doks.digitalocean.com/managed: "true"
      k8s-app: kube-dns
      pod-template-hash: 5dd67759cd
    name: coredns-5dd67759cd-4z7vm
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5dd67759cd
      uid: 0f9edb5d-0d6a-47b4-bd09-e49e2ea257b2
    resourceVersion: "322927321"
    uid: dfd511a5-e4b1-4a70-871f-27f7f7b0959f
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: doks.digitalocean.com/gpu-brand
              operator: DoesNotExist
          weight: 50
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: docker.io/coredns/coredns:1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bpk24
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - key: nvidia.com/gpu
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - configMap:
        defaultMode: 420
        name: coredns-custom
        optional: true
      name: custom-config-volume
    - name: kube-api-access-bpk24
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f629794d4da3ee669ba103335774b2840e14193457e9e7cf539b01f32c2f4b17
      image: docker.io/coredns/coredns:1.10.1
      imageID: docker.io/coredns/coredns@sha256:a0ead06651cf580044aeb0a0feba63591858fb2e43ade8c9dea45a6a89ae7e5e
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:38Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.11
    podIPs:
    - ip: 10.244.0.11
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:04:00Z"
    generateName: coredns-5dd67759cd-
    labels:
      doks.digitalocean.com/managed: "true"
      k8s-app: kube-dns
      pod-template-hash: 5dd67759cd
    name: coredns-5dd67759cd-qmqrm
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5dd67759cd
      uid: 0f9edb5d-0d6a-47b4-bd09-e49e2ea257b2
    resourceVersion: "322927692"
    uid: 2d961c97-3488-432d-931d-8c296c00f9c2
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: doks.digitalocean.com/gpu-brand
              operator: DoesNotExist
          weight: 50
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: docker.io/coredns/coredns:1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /etc/coredns/custom
        name: custom-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8qskb
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - key: nvidia.com/gpu
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - configMap:
        defaultMode: 420
        name: coredns-custom
        optional: true
      name: custom-config-volume
    - name: kube-api-access-8qskb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:04:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://0dfa16023f605531d6b69fb886c4aa7d2be9476e8358815d60101f3fc1929169
      image: docker.io/coredns/coredns:1.10.1
      imageID: docker.io/coredns/coredns@sha256:a0ead06651cf580044aeb0a0feba63591858fb2e43ade8c9dea45a6a89ae7e5e
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:04:02Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.78
    podIPs:
    - ip: 10.244.0.78
    qosClass: Burstable
    startTime: "2024-11-28T04:04:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: resource-requirements
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: cpc-bridge-proxy-
    labels:
      app: cpc-bridge-proxy
      controller-revision-hash: 5d57b9b6f5
      doks.digitalocean.com/managed: "true"
      pod-template-generation: "5"
    name: cpc-bridge-proxy-7c8jk
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: cpc-bridge-proxy
      uid: 7b96c765-f449-42a0-bc76-4158901d5989
    resourceVersion: "322926923"
    uid: 311d8c6a-7047-43f0-b77b-8411ecbce7a9
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
    automountServiceAccountToken: false
    containers:
    - image: digitalocean/cpbridge:1.25.1
      imagePullPolicy: IfNotPresent
      name: cpc-bridge-proxy
      resources:
        requests:
          cpu: 100m
          memory: 75Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/nginx
        name: cpc-bridge-proxy-config
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    imagePullSecrets:
    - name: josemi-registry
    - name: josemy-registry
    initContainers:
    - command:
      - /bin/bash
      - -c
      - |
        set -o errexit
        set -o pipefail
        set -o nounset
        ipt_nat="iptables-legacy -t nat"
        # Avoid racing with kube-proxy on the initial iptables rules population which makes the rule order indeterministic.
        until ${ipt_nat} --list KUBE-SERVICES > /dev/null; do echo "waiting for kube-proxy to populate iptables rules"; sleep 3; done
        ipt_output_args="OUTPUT -p tcp -d 10.245.0.1/32 --dport 443 -j DNAT --to-destination 100.65.58.73:16443"
        ipt_prerouting_args="PREROUTING -p tcp -d 100.65.58.73 --dport 443 -j DNAT --to-destination 100.65.58.73:16443"
        ${ipt_nat} --check ${ipt_output_args} || ${ipt_nat} --insert ${ipt_output_args}
        ${ipt_nat} --check ${ipt_prerouting_args} || ${ipt_nat} --insert ${ipt_prerouting_args}
      image: digitalocean/cpbridge:1.25.1
      imagePullPolicy: IfNotPresent
      name: init-iptables
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: cpc-bridge-proxy-config
      name: cpc-bridge-proxy-config
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4bb8d4db76b470c82034ee002e86ec3cab21fddc0b4e65246a17e89e1297cf79
      image: docker.io/digitalocean/cpbridge:1.25.1
      imageID: docker.io/digitalocean/cpbridge@sha256:bad0e515066cdaf5a1248761b0e47ffe44a878395534fe13dec2cd17624ab1cc
      lastState: {}
      name: cpc-bridge-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:02:58Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://cc9f2cb83cb5a02b6020c3578d4b8136229977d3d20e3a9d99fa9d51eb853997
      image: docker.io/digitalocean/cpbridge:1.25.1
      imageID: docker.io/digitalocean/cpbridge@sha256:bad0e515066cdaf5a1248761b0e47ffe44a878395534fe13dec2cd17624ab1cc
      lastState: {}
      name: init-iptables
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://cc9f2cb83cb5a02b6020c3578d4b8136229977d3d20e3a9d99fa9d51eb853997
          exitCode: 0
          finishedAt: "2024-11-28T04:02:57Z"
          reason: Completed
          startedAt: "2024-11-28T04:02:57Z"
    phase: Running
    podIP: 10.114.0.3
    podIPs:
    - ip: 10.114.0.3
    qosClass: Burstable
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: privileged-containers,non-root-user,resource-requirements,hostpath-volume
      kubectl.kubernetes.io/default-container: csi-do-plugin
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: csi-do-node-
    labels:
      app: csi-do-node
      controller-revision-hash: 55656988db
      doks.digitalocean.com/managed: "true"
      pod-template-generation: "9"
      role: csi-do
    name: csi-do-node-q5f78
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: csi-do-node
      uid: 02b20ca4-eeb7-422c-a803-bb1bb36b4bb0
    resourceVersion: "322926895"
    uid: bef85205-8844-47e7-8231-d25e3858acd8
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
    containers:
    - args:
      - --v=5
      - --csi-address=$(ADDRESS)
      - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)
      env:
      - name: ADDRESS
        value: /csi/csi.sock
      - name: DRIVER_REG_SOCK_PATH
        value: /var/lib/kubelet/plugins/dobs.csi.digitalocean.com/csi.sock
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.8.0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/sh
            - -c
            - rm -rf /registration/dobs.csi.digitalocean.com /registration/dobs.csi.digitalocean.com-reg.sock
      name: csi-node-driver-registrar
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi/
        name: plugin-dir
      - mountPath: /registration/
        name: registration-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dddg7
        readOnly: true
    - args:
      - --endpoint=$(CSI_ENDPOINT)
      - --validate-attachment=true
      - --volume-limit=15
      - --url=https://api.digitalocean.com
      - --driver-name=dobs.csi.digitalocean.com
      env:
      - name: CSI_ENDPOINT
        value: unix:///csi/csi.sock
      image: docker.io/digitalocean/do-csi-plugin:v4.11.0
      imagePullPolicy: Always
      name: csi-do-plugin
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          add:
          - SYS_ADMIN
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi
        name: plugin-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: Bidirectional
        name: pods-mount-dir
      - mountPath: /dev
        name: device-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dddg7
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: csi-do-node-sa
    serviceAccountName: csi-do-node-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/kubelet/plugins_registry/
        type: DirectoryOrCreate
      name: registration-dir
    - hostPath:
        path: /var/lib/kubelet/plugins/dobs.csi.digitalocean.com
        type: DirectoryOrCreate
      name: plugin-dir
    - hostPath:
        path: /var/lib/kubelet
        type: Directory
      name: pods-mount-dir
    - hostPath:
        path: /dev
        type: ""
      name: device-dir
    - name: kube-api-access-dddg7
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://439646b0ffc283aa5fb39efbd7fe6d6fb6983a027527aede31677387fe1e20e2
      image: docker.io/digitalocean/do-csi-plugin:v4.11.0
      imageID: docker.io/digitalocean/do-csi-plugin@sha256:308ed578f2f94d982a0023db326dd9adeededf73a80736c06219235e3b1a8113
      lastState: {}
      name: csi-do-plugin
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:02:56Z"
    - containerID: containerd://9d9dde62eca91888525fc435889543a13c892522812004b6028b6f5e78343fbf
      image: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.8.0
      imageID: registry.k8s.io/sig-storage/csi-node-driver-registrar@sha256:f6717ce72a2615c7fbc746b4068f788e78579c54c43b8716e5ce650d97af2df1
      lastState: {}
      name: csi-node-driver-registrar
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:02:48Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.114.0.3
    podIPs:
    - ip: 10.114.0.3
    qosClass: BestEffort
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: resource-requirements,hostpath-volume
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: do-node-agent-
    labels:
      app: do-node-agent
      controller-revision-hash: 56c5799fc6
      doks.digitalocean.com/managed: "true"
      pod-template-generation: "12"
    name: do-node-agent-m8dqv
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: do-node-agent
      uid: 98a46a75-410a-4ae1-b244-3969158d42c0
    resourceVersion: "322927004"
    uid: a05db920-6fea-472a-837d-899d75362369
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
    containers:
    - args:
      - '@/etc/config/do-agent-config'
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --k8s-metrics-path=http://kube-state-metrics.kube-system.svc.cluster.local:8080/metrics
      - --additional-label=kubernetes_cluster_uuid:115f9fa6-df7d-40ba-910d-1dcc2c6d9c72
      command:
      - /bin/do-agent
      image: docker.io/digitalocean/do-agent:3.16.9
      imagePullPolicy: IfNotPresent
      name: do-node-agent
      resources:
        limits:
          memory: 300Mi
        requests:
          cpu: 102m
          memory: 80Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /etc/config
        name: dynamic-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9drnn
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - sh
      - -c
      - |
        set -o errexit
        set -o pipefail
        set -o nounset

        KUBECTL=/host/usr/bin/kubectl
        POOL_ID="$(${KUBECTL} get node ${NODE_NAME} -o jsonpath='{.metadata.labels.doks\.digitalocean\.com/node-pool-id}')"
        [[ -z "${POOL_ID}" ]] && echo "Pool ID label missing" && exit 1
        echo "--additional-label=kubernetes_node_pool_uuid:${POOL_ID}" > /etc/config/do-agent-config
        echo "Pool ID configured: ${POOL_ID}"
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: gcr.io/distroless/static-debian12:debug-nonroot-amd64
      imagePullPolicy: IfNotPresent
      name: dynamic-config
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: dynamic-config
      - mountPath: /host/usr/bin/kubectl
        name: host-kubectl
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9drnn
        readOnly: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: do-agent
    serviceAccountName: do-agent
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: dynamic-config
    - hostPath:
        path: /usr/bin/kubectl
        type: File
      name: host-kubectl
    - name: kube-api-access-9drnn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:05Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://794c7fd4ec84e9b84cc1c237d639c5a79a75e80c6b776d1691b3687446d8403d
      image: docker.io/digitalocean/do-agent:3.16.9
      imageID: docker.io/digitalocean/do-agent@sha256:19b2340bcebf70627c498ecee3e846b47dc1f4570e106555473d21907629587e
      lastState: {}
      name: do-node-agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:08Z"
    hostIP: 10.114.0.3
    initContainerStatuses:
    - containerID: containerd://a835c4cc88dc7c46b9b182b20ca60f57632429d967b27c84f533a78d8cc78fd0
      image: gcr.io/distroless/static-debian12:debug-nonroot-amd64
      imageID: gcr.io/distroless/static-debian12@sha256:0b6217d275396204e13e9f4798715decb0ff0a210ab70a128acdd9d1c2fc6bd6
      lastState: {}
      name: dynamic-config
      ready: true
      restartCount: 2
      started: false
      state:
        terminated:
          containerID: containerd://a835c4cc88dc7c46b9b182b20ca60f57632429d967b27c84f533a78d8cc78fd0
          exitCode: 0
          finishedAt: "2024-11-28T04:03:05Z"
          reason: Completed
          startedAt: "2024-11-28T04:03:05Z"
    phase: Running
    podIP: 10.114.0.3
    podIPs:
    - ip: 10.114.0.3
    qosClass: Burstable
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      clusterlint.digitalocean.com/disabled-checks: resource-requirements
    creationTimestamp: "2024-11-28T04:01:37Z"
    generateName: hubble-relay-b86d45476-
    labels:
      app.kubernetes.io/name: hubble-relay
      app.kubernetes.io/part-of: cilium
      doks.digitalocean.com/managed: "true"
      k8s-app: hubble-relay
      pod-template-hash: b86d45476
    name: hubble-relay-b86d45476-mlf99
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: hubble-relay-b86d45476
      uid: 3565d068-6cb9-49a6-91aa-1fee5fc1e7b9
    resourceVersion: "322927354"
    uid: 7a05722c-c002-4842-b774-261d36123623
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: doks.digitalocean.com/gpu-brand
              operator: DoesNotExist
          weight: 100
      podAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              k8s-app: cilium
          topologyKey: kubernetes.io/hostname
    automountServiceAccountToken: false
    containers:
    - args:
      - serve
      command:
      - hubble-relay
      image: quay.io/cilium/hubble-relay:v1.14.10@sha256:c156c4fc2da520d2876142ea17490440b95431a1be755d2050e72115a495cfd0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: grpc
        timeoutSeconds: 1
      name: hubble-relay
      ports:
      - containerPort: 4245
        name: grpc
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: grpc
        timeoutSeconds: 1
      resources: {}
      securityContext:
        capabilities:
          drop:
          - ALL
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hubble-relay
        name: config
        readOnly: true
      - mountPath: /var/lib/hubble-relay/tls
        name: tls
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65532
    serviceAccount: hubble-relay
    serviceAccountName: hubble-relay
    terminationGracePeriodSeconds: 1
    tolerations:
    - key: nvidia.com/gpu
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: config.yaml
          path: config.yaml
        name: hubble-relay-config
      name: config
    - name: tls
      projected:
        defaultMode: 256
        sources:
        - secret:
            items:
            - key: tls.crt
              path: client.crt
            - key: tls.key
              path: client.key
            - key: ca.crt
              path: hubble-server-ca.crt
            name: hubble-relay-client-certs
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://11d08b7e882c856a11a6002f3a3feeab5bcc1c95148f84f810b09c584153f6eb
      image: sha256:c1c3c23052b596a196bafdde792de08748eb9d634c3a9fd75f3d8264d8b7ced9
      imageID: quay.io/cilium/hubble-relay@sha256:c156c4fc2da520d2876142ea17490440b95431a1be755d2050e72115a495cfd0
      lastState: {}
      name: hubble-relay
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:41Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.59
    podIPs:
    - ip: 10.244.0.59
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      clusterlint.digitalocean.com/disabled-checks: resource-requirements
    creationTimestamp: "2024-11-28T04:01:38Z"
    generateName: hubble-ui-b755f4f46-
    labels:
      app.kubernetes.io/name: hubble-ui
      app.kubernetes.io/part-of: cilium
      doks.digitalocean.com/managed: "true"
      k8s-app: hubble-ui
      pod-template-hash: b755f4f46
    name: hubble-ui-b755f4f46-854rx
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: hubble-ui-b755f4f46
      uid: 8e33abcc-d802-41ed-a834-76bb616fb46d
    resourceVersion: "322927466"
    uid: 48aaf535-9798-4f62-9dab-4b9a15ede0de
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: doks.digitalocean.com/gpu-brand
              operator: DoesNotExist
          weight: 100
    automountServiceAccountToken: true
    containers:
    - image: quay.io/cilium/hubble-ui:v0.13.0@sha256:7d663dc16538dd6e29061abd1047013a645e6e69c115e008bee9ea9fef9a6666
      imagePullPolicy: IfNotPresent
      name: frontend
      ports:
      - containerPort: 8081
        name: http
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/nginx/conf.d/default.conf
        name: hubble-ui-nginx-conf
        subPath: nginx.conf
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kgs9j
        readOnly: true
    - env:
      - name: EVENTS_SERVER_PORT
        value: "8090"
      - name: FLOWS_API_ADDR
        value: hubble-relay:80
      image: quay.io/cilium/hubble-ui-backend:v0.13.0@sha256:1e7657d997c5a48253bb8dc91ecee75b63018d16ff5e5797e5af367336bc8803
      imagePullPolicy: IfNotPresent
      name: backend
      ports:
      - containerPort: 8090
        name: grpc
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kgs9j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: hubble-ui
    serviceAccountName: hubble-ui
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: nvidia.com/gpu
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: hubble-ui-nginx
      name: hubble-ui-nginx-conf
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-kgs9j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f0368cd10559b8114e4f3ca159c86795bbae00e1c616374e9ec1d48d518ccaa4
      image: sha256:1ea21544e094404b724cc15293af153f44149b5b081f32d4d43967b88bc98b3f
      imageID: quay.io/cilium/hubble-ui-backend@sha256:1e7657d997c5a48253bb8dc91ecee75b63018d16ff5e5797e5af367336bc8803
      lastState: {}
      name: backend
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:48Z"
    - containerID: containerd://0f3ac090e1360be4f9dbad03dbb3fcd904bbe58a3d3802d8152c5aee29a1d2b2
      image: sha256:78000f56b0cffca17d887126b1f52527f6c5e8104e3dd5ac8344a29c4ae38713
      imageID: quay.io/cilium/hubble-ui@sha256:7d663dc16538dd6e29061abd1047013a645e6e69c115e008bee9ea9fef9a6666
      lastState: {}
      name: frontend
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:36Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.116
    podIPs:
    - ip: 10.244.0.116
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: resource-requirements
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: konnectivity-agent-
    labels:
      controller-revision-hash: 5677dccc4
      doks.digitalocean.com/managed: "true"
      k8s-app: konnectivity-agent
      pod-template-generation: "5"
    name: konnectivity-agent-6b64q
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: konnectivity-agent
      uid: c6460f74-9ffb-430e-82eb-c070fd625c74
    resourceVersion: "322927221"
    uid: 0f510e7e-5201-4610-a208-5b97de9ef002
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
    containers:
    - args:
      - --logtostderr=true
      - --ca-cert=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - --proxy-server-port=8132
      - --admin-server-port=8133
      - --health-server-port=8134
      - --keepalive-time=5m
      - --service-account-token-path=/var/run/secrets/tokens/konnectivity-agent-token
      - --proxy-server-host=115f9fa6-df7d-40ba-910d-1dcc2c6d9c72.k8s.ondigitalocean.com
      command:
      - /proxy-agent
      image: registry.k8s.io/kas-network-proxy/proxy-agent:v0.1.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8134
          scheme: HTTP
        initialDelaySeconds: 15
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: konnectivity-agent
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/tokens
        name: konnectivity-agent-token
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qzpj6
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: konnectivity-agent
    serviceAccountName: konnectivity-agent
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: konnectivity-agent-token
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            audience: system:konnectivity-server
            expirationSeconds: 3600
            path: konnectivity-agent-token
    - name: kube-api-access-qzpj6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://403986d85c7f3ee3bf7039c6bbcefcda4b86d7787f4bfbf1674dc1456a6c09fb
      image: registry.k8s.io/kas-network-proxy/proxy-agent:v0.1.4
      imageID: registry.k8s.io/kas-network-proxy/proxy-agent@sha256:ec6e74c7a95d1624c0690e8bfaca7f425b9a696656e9ccc4b0b7bf5d399b7bd4
      lastState: {}
      name: konnectivity-agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:25Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.85
    podIPs:
    - ip: 10.244.0.85
    qosClass: BestEffort
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      clusterlint.digitalocean.com/disabled-checks: privileged-containers,non-root-user,resource-requirements,hostpath-volume
    creationTimestamp: "2024-11-28T04:02:45Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 56fb8cb774
      doks.digitalocean.com/managed: "true"
      k8s-app: kube-proxy
      pod-template-generation: "14"
      tier: node
    name: kube-proxy-8zmzg
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: b6f46663-36d9-4e54-825e-60af723c2753
    resourceVersion: "322926849"
    uid: 3af20e9a-d971-410d-afb2-53422794e4cb
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - pool-hr3r15rhq-g2t2x
    containers:
    - command:
      - kube-proxy
      - --config=/etc/kubernetes/config/kube-proxy-config.yaml
      image: registry.k8s.io/kube-proxy:v1.28.14
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources:
        requests:
          memory: 125Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes
        name: kube-proxy-kubeconfig
        readOnly: true
      - mountPath: /etc/kubernetes/config
        name: kube-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b8xz4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: kube-proxy-kubeconfig
      secret:
        defaultMode: 420
        secretName: kube-proxy
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy-config
    - name: kube-api-access-b8xz4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:02:45Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://baa5ae3273ddc208f1420699d979372991c22c1d2065ea03b7e47270db52ae3a
      image: registry.k8s.io/kube-proxy:v1.28.14
      imageID: registry.k8s.io/kube-proxy@sha256:1154933b96101e3ed1c42fea144453ff3c290e2365b758bf36d7254ef29ca3e8
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:02:50Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.114.0.3
    podIPs:
    - ip: 10.114.0.3
    qosClass: Burstable
    startTime: "2024-11-28T04:02:45Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:35Z"
    generateName: sealed-secrets-67bb8b964d-
    labels:
      app.kubernetes.io/instance: sealed-secrets
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: sealed-secrets
      app.kubernetes.io/version: 0.27.1
      helm.sh/chart: sealed-secrets-2.4.5
      pod-template-hash: 67bb8b964d
    name: sealed-secrets-67bb8b964d-99q9m
    namespace: sealed-secrets
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: sealed-secrets-67bb8b964d
      uid: 7c2504c5-ce87-42d7-85cf-55f200556e38
    resourceVersion: "322927405"
    uid: 44c328ce-f119-4a91-a796-2dbf5d64ca4f
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/instance: sealed-secrets
                app.kubernetes.io/name: sealed-secrets
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: true
    containers:
    - args:
      - --key-prefix
      - sealed-secrets-key
      - --update-status
      command:
      - /controller
      image: docker.io/bitnami/sealed-secrets-controller:0.27.1-debian-12-r3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: http
        timeoutSeconds: 1
      name: sealed-secrets
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: http
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: 150m
          ephemeral-storage: 2Gi
          memory: 192Mi
        requests:
          cpu: 100m
          ephemeral-storage: 50Mi
          memory: 128Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: empty-dir
        subPath: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hmt7b
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: sealed-secrets
    serviceAccountName: sealed-secrets
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: empty-dir
    - name: kube-api-access-hmt7b
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d39da7e4308cc90e8049c2b9f0c90746a832aba8876d31b573a2f68c5593166b
      image: docker.io/bitnami/sealed-secrets-controller:0.27.1-debian-12-r3
      imageID: docker.io/bitnami/sealed-secrets-controller@sha256:02c63e0d249f1a5afd46fc87eb4035ca059b74164b96139e73a6329e85fcd045
      lastState: {}
      name: sealed-secrets
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:39Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.120
    podIPs:
    - ip: 10.244.0.120
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:32Z"
    generateName: tekton-pipelines-remote-resolvers-6cccbf8d4c-
    labels:
      app: tekton-pipelines-resolvers
      app.kubernetes.io/component: resolvers
      app.kubernetes.io/instance: default
      app.kubernetes.io/name: resolvers
      app.kubernetes.io/part-of: tekton-pipelines
      app.kubernetes.io/version: v0.45.0
      pipeline.tekton.dev/release: v0.45.0
      pod-template-hash: 6cccbf8d4c
      version: v0.45.0
    name: tekton-pipelines-remote-resolvers-6cccbf8d4c-npfp9
    namespace: tekton-pipelines-resolvers
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: tekton-pipelines-remote-resolvers-6cccbf8d4c
      uid: b4b200aa-95f7-4399-8989-bf206b8984ca
    resourceVersion: "322927360"
    uid: 12bdd095-d0fc-4570-a8bd-fd472ce33df8
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: resolvers
                app.kubernetes.io/instance: default
                app.kubernetes.io/name: resolvers
                app.kubernetes.io/part-of: tekton-pipelines
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: CONFIG_FEATURE_FLAGS_NAME
        value: feature-flags
      - name: CONFIG_LEADERELECTION_NAME
        value: config-leader-election
      - name: METRICS_DOMAIN
        value: tekton.dev/resolution
      - name: ARTIFACT_HUB_API
        value: https://artifacthub.io/
      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/resolvers:v0.45.0@sha256:5bd5240ccd89e0b81796aa8b8bbb4feb2162e63dda1cb0a95e315c9fadeb7ec8
      imagePullPolicy: IfNotPresent
      name: controller
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      resources:
        limits:
          cpu: "1"
          memory: 4Gi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-x8mgb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: tekton-pipelines-resolvers
    serviceAccountName: tekton-pipelines-resolvers
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-x8mgb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2fb011485de78f55a86a45fd678bd580617c3c3f56298bb45c0311d4a67ed9dc
      image: sha256:a5c5ba757e7b2f181d0d994e0f4dd175cae7fe6c2ad6dbc94cb5e0f7d20d4586
      imageID: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/resolvers@sha256:5bd5240ccd89e0b81796aa8b8bbb4feb2162e63dda1cb0a95e315c9fadeb7ec8
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:41Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.5
    podIPs:
    - ip: 10.244.0.5
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:32Z"
    generateName: tekton-dashboard-58d5bd4644-
    labels:
      app: tekton-dashboard
      app.kubernetes.io/component: dashboard
      app.kubernetes.io/instance: default
      app.kubernetes.io/name: dashboard
      app.kubernetes.io/part-of: tekton-dashboard
      app.kubernetes.io/version: v0.43.0
      pod-template-hash: 58d5bd4644
    name: tekton-dashboard-58d5bd4644-qpr6r
    namespace: tekton-pipelines
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: tekton-dashboard-58d5bd4644
      uid: 2ad811d5-514a-4bd2-9e8d-31b87d49f3d0
    resourceVersion: "322927313"
    uid: 39eb6248-a27d-48ac-8f65-c81ff0586cf3
  spec:
    containers:
    - args:
      - --port=9097
      - --logout-url=
      - --pipelines-namespace=tekton-pipelines
      - --triggers-namespace=tekton-pipelines
      - --read-only=true
      - --log-level=info
      - --log-format=json
      - --namespace=
      - --namespaces=
      - --stream-logs=true
      - --external-logs=
      env:
      - name: INSTALLED_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: gcr.io/tekton-releases/github.com/tektoncd/dashboard/cmd/dashboard:v0.43.0@sha256:70ca3d57d795c38b5a16e7b69bde8550337b7b2ea3183d94b022f0388b0ee61d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: 9097
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: tekton-dashboard
      ports:
      - containerPort: 9097
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: 9097
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4lq97
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: tekton-dashboard
    serviceAccountName: tekton-dashboard
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-4lq97
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://89a567c1d730dd8d70005a67a393289ce503c5114d9cd37d92bbc02ae049b3cb
      image: sha256:906120dca0b26193d26ab997bbda272098eb7021eb19bd529c57574844b0a7a9
      imageID: gcr.io/tekton-releases/github.com/tektoncd/dashboard/cmd/dashboard@sha256:70ca3d57d795c38b5a16e7b69bde8550337b7b2ea3183d94b022f0388b0ee61d
      lastState: {}
      name: tekton-dashboard
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:39Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.64
    podIPs:
    - ip: 10.244.0.64
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:36Z"
    generateName: tekton-pipelines-controller-9675574d7-
    labels:
      app: tekton-pipelines-controller
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: default
      app.kubernetes.io/name: controller
      app.kubernetes.io/part-of: tekton-pipelines
      app.kubernetes.io/version: v0.45.0
      pipeline.tekton.dev/release: v0.45.0
      pod-template-hash: 9675574d7
      version: v0.45.0
    name: tekton-pipelines-controller-9675574d7-8bcgf
    namespace: tekton-pipelines
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: tekton-pipelines-controller-9675574d7
      uid: 34489c93-170c-4b88-9024-d979376cddfe
    resourceVersion: "322927391"
    uid: ac7bf128-7a45-438c-9a71-a53246a3103a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: NotIn
              values:
              - windows
    containers:
    - args:
      - -git-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/git-init:v0.45.0@sha256:8ab0f58d8381b0b71f5b2bae1f63522989d739e3154d8cab1bacfa0ef5317214
      - -entrypoint-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/entrypoint:v0.45.0@sha256:9e1ed138383b2266a7916cd3a501fb50335da36d4fd72fd0a4de2aac142cf4b4
      - -nop-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/nop:v0.45.0@sha256:3314b1f7222c41ab6e191bb4d4e13b519cc1c2f71f66e29ce86d9eaf611808f0
      - -sidecarlogresults-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/sidecarlogresults:v0.45.0@sha256:3e2d834c4820f06c44a79362d17b847bb0f108a385a932e5f5fdb32160b38b3a
      - -imagedigest-exporter-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/imagedigestexporter:v0.45.0@sha256:80d09ba9f2aa293a0d4b93ff44a56d6cbeb7669cf4108b63d8a3a94c0b446509
      - -workingdirinit-image
      - gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/workingdirinit:v0.45.0@sha256:52fe1b196c2f473cde962745768787ad48b9fd15544a5d2c69bd40c2ade0a461
      - -gsutil-image
      - gcr.io/google.com/cloudsdktool/cloud-sdk@sha256:27b2c22bf259d9bc1a291e99c63791ba0c27a04d2db0a43241ba0f1f20f4067f
      - -shell-image
      - cgr.dev/chainguard/busybox@sha256:19f02276bf8dbdd62f069b922f10c65262cc34b710eea26ff928129a736be791
      - -shell-image-win
      - mcr.microsoft.com/powershell:nanoserver@sha256:b6d5ff841b78bdf2dfed7550000fd4f3437385b8fa686ec0f010be24777654d6
      env:
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_DEFAULTS_NAME
        value: config-defaults
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: CONFIG_ARTIFACT_BUCKET_NAME
        value: config-artifact-bucket
      - name: CONFIG_ARTIFACT_PVC_NAME
        value: config-artifact-pvc
      - name: CONFIG_FEATURE_FLAGS_NAME
        value: feature-flags
      - name: CONFIG_LEADERELECTION_NAME
        value: config-leader-election
      - name: CONFIG_SPIRE
        value: config-spire
      - name: CONFIG_TRUSTED_RESOURCES_NAME
        value: config-trusted-resources
      - name: SSL_CERT_FILE
        value: /etc/config-registry-cert/cert
      - name: SSL_CERT_DIR
        value: /etc/ssl/certs
      - name: METRICS_DOMAIN
        value: tekton.dev/pipeline
      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/controller:v0.45.0@sha256:8a302dab54484bbb83d46ff9455b077ea51c1c189641dcda12575f8301bfb257
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: probes
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: tekton-pipelines-controller
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8080
        name: probes
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: probes
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config-logging
        name: config-logging
      - mountPath: /etc/config-registry-cert
        name: config-registry-cert
      - mountPath: /etc/verification-secrets
        name: verification-secrets
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-l7cqx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: tekton-pipelines-controller
    serviceAccountName: tekton-pipelines-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: config-logging
      name: config-logging
    - configMap:
        defaultMode: 420
        name: config-registry-cert
      name: config-registry-cert
    - name: verification-secrets
      secret:
        defaultMode: 420
        optional: true
        secretName: verification-secrets
    - name: kube-api-access-l7cqx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://54d115008d3498ca9e070ad37dd4e1f7691bc9cdd749f91dad8f240c3a3f533d
      image: sha256:431fcfcdb44dace7c38b783bf487c6abb5902f4a98e2084dc5ecd273ac215d45
      imageID: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/controller@sha256:8a302dab54484bbb83d46ff9455b077ea51c1c189641dcda12575f8301bfb257
      lastState: {}
      name: tekton-pipelines-controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:35Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.30
    podIPs:
    - ip: 10.244.0.30
    qosClass: BestEffort
    startTime: "2024-11-28T04:03:14Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-28T04:01:35Z"
    generateName: tekton-pipelines-webhook-58b5cbb7dd-
    labels:
      app: tekton-pipelines-webhook
      app.kubernetes.io/component: webhook
      app.kubernetes.io/instance: default
      app.kubernetes.io/name: webhook
      app.kubernetes.io/part-of: tekton-pipelines
      app.kubernetes.io/version: v0.45.0
      pipeline.tekton.dev/release: v0.45.0
      pod-template-hash: 58b5cbb7dd
      version: v0.45.0
    name: tekton-pipelines-webhook-58b5cbb7dd-vs8nk
    namespace: tekton-pipelines
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: tekton-pipelines-webhook-58b5cbb7dd
      uid: c22f6a13-3921-40b7-a361-12f8f83181c5
    resourceVersion: "322927513"
    uid: 97148766-30a6-4466-a6c6-2cce4e58030f
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/os
              operator: NotIn
              values:
              - windows
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: webhook
                app.kubernetes.io/instance: default
                app.kubernetes.io/name: webhook
                app.kubernetes.io/part-of: tekton-pipelines
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - env:
      - name: SYSTEM_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CONFIG_LOGGING_NAME
        value: config-logging
      - name: CONFIG_OBSERVABILITY_NAME
        value: config-observability
      - name: CONFIG_LEADERELECTION_NAME
        value: config-leader-election
      - name: CONFIG_FEATURE_FLAGS_NAME
        value: feature-flags
      - name: WEBHOOK_PORT
        value: "8443"
      - name: WEBHOOK_ADMISSION_CONTROLLER_NAME
        value: webhook.pipeline.tekton.dev
      - name: WEBHOOK_SERVICE_NAME
        value: tekton-pipelines-webhook
      - name: WEBHOOK_SECRET_NAME
        value: webhook-certs
      - name: METRICS_DOMAIN
        value: tekton.dev/pipeline
      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/webhook:v0.45.0@sha256:07390c988b1c651c4810e9f7b15a88dfce8030845a429cf19b762a0d50e18ca7
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /health
          port: probes
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: webhook
      ports:
      - containerPort: 9090
        name: metrics
        protocol: TCP
      - containerPort: 8008
        name: profiling
        protocol: TCP
      - containerPort: 8443
        name: https-webhook
        protocol: TCP
      - containerPort: 8080
        name: probes
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readiness
          port: probes
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 500m
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rjkdv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: pool-hr3r15rhq-g2t2x
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: tekton-pipelines-webhook
    serviceAccountName: tekton-pipelines-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rjkdv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-28T04:03:14Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://41ca31064121d181c35e5a616d06adbce4bab99e98e7c9c9e1b1b41e89263921
      image: sha256:85063e4c82d0e21493340cf1eff86f1caa843d96ea0ac0e9de05b8c334c11251
      imageID: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/webhook@sha256:07390c988b1c651c4810e9f7b15a88dfce8030845a429cf19b762a0d50e18ca7
      lastState: {}
      name: webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-28T04:03:42Z"
    hostIP: 10.114.0.3
    phase: Running
    podIP: 10.244.0.2
    podIPs:
    - ip: 10.244.0.2
    qosClass: Burstable
    startTime: "2024-11-28T04:03:14Z"
kind: List
metadata:
  resourceVersion: ""
